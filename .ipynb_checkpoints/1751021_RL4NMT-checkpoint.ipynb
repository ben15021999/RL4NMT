{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f5e8b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROBLEM = \"translate_zhen_wmt17\" # We chose a problem translation English to French with 32.768 vocabulary\n",
    "MODEL = \"transformer\" # Our model\n",
    "HPARAMS = \"zhen_wmt17_transformer_rl_delta_setting\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e2e78c94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.platform.gfile.GFile at 0x23d6f8cae48>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "DATA_DIR = os.path.expanduser(\"/transformer_data/zhen/\") # This folder contain the data\n",
    "TMP_DIR = os.path.expanduser(\"/t2t_datagen/\")\n",
    "TRAIN_DIR = os.path.expanduser(\"model/\" + HPARAMS) # This folder contain the model\n",
    "EXPORT_DIR = os.path.expanduser(TRAIN_DIR) # This folder contain the exported model for production\n",
    "TRANSLATIONS_DIR = os.path.expanduser(\"/translation/\") # This folder contain  all translated sequence\n",
    "EVENT_DIR = os.path.expanduser(\"/event/\") # Test the BLEU score\n",
    "USR_DIR = os.path.expanduser(\"/zhen_wmt17/\") # This folder contains our data that we want to add\n",
    " \n",
    "tf.io.gfile.GFile(DATA_DIR)\n",
    "tf.io.gfile.GFile(TMP_DIR)\n",
    "tf.io.gfile.GFile(TRAIN_DIR)\n",
    "tf.io.gfile.GFile(EXPORT_DIR)\n",
    "tf.io.gfile.GFile(TRANSLATIONS_DIR)\n",
    "tf.io.gfile.GFile(EVENT_DIR)\n",
    "tf.io.gfile.GFile(USR_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0e6112c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.platform.gfile.GFile at 0x23d6f7be3c8>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DECODE_FILE = DATA_DIR + \"/decode_this.txt\"\n",
    "REF_FILE = DATA_DIR + \"ref.zh\"\n",
    "tf.io.gfile.GFile(DECODE_FILE)\n",
    "tf.io.gfile.GFile(REF_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "010bc2d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "BEAM_SIZE=6\n",
    "ALPHA=1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d743f345",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/zhen_wmt17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\Anaconda3\\envs\\a\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:469: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\ASUS\\Anaconda3\\envs\\a\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:470: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\ASUS\\Anaconda3\\envs\\a\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:471: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\ASUS\\Anaconda3\\envs\\a\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:472: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\ASUS\\Anaconda3\\envs\\a\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:473: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\ASUS\\Anaconda3\\envs\\a\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:476: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "INFO:tensorflow:Importing user module zhen_wmt17 from path /\n",
      "INFO:tensorflow:Loading and processing source vocabulary from: vocab.src\n",
      "Traceback (most recent call last):\n",
      "  File \"./tensor2tensor/bin/t2t-decoder\", line 103, in <module>\n",
      "    tf.app.run()\n",
      "  File \"C:\\Users\\ASUS\\Anaconda3\\envs\\a\\lib\\site-packages\\tensorflow\\python\\platform\\app.py\", line 48, in run\n",
      "    _sys.exit(main(_sys.argv[:1] + flags_passthrough))\n",
      "  File \"./tensor2tensor/bin/t2t-decoder\", line 78, in main\n",
      "    trainer_utils.add_problem_hparams(hparams, FLAGS.problems)  # hparams including modalities, vocabulary\n",
      "  File \"C:\\Users\\ASUS\\Anaconda3\\envs\\a\\lib\\site-packages\\tensor2tensor-1.2.9-py3.6.egg\\tensor2tensor\\utils\\trainer_utils.py\", line 284, in add_problem_hparams\n",
      "    p_hparams = problem.get_hparams(hparams)    # contains vocabulary, inputs/targets modality\n",
      "  File \"C:\\Users\\ASUS\\Anaconda3\\envs\\a\\lib\\site-packages\\tensor2tensor-1.2.9-py3.6.egg\\tensor2tensor\\data_generators\\problem.py\", line 293, in get_hparams\n",
      "    self.get_feature_encoders(data_dir)  # vocabulary\n",
      "  File \"C:\\Users\\ASUS\\Anaconda3\\envs\\a\\lib\\site-packages\\tensor2tensor-1.2.9-py3.6.egg\\tensor2tensor\\data_generators\\problem.py\", line 283, in get_feature_encoders\n",
      "    self._encoders = self.feature_encoders(data_dir)\n",
      "  File \"C:\\Users\\ASUS\\Anaconda3\\envs\\a\\lib\\site-packages\\tensor2tensor-1.2.9-py3.6.egg\\zhen_wmt17\\zhen_wmt17.py\", line 142, in feature_encoders\n",
      "    with open(os.path.join(data_dir,_ZHEN_VOCAB_FILES[0]), 'rb') as f:\n",
      "FileNotFoundError: [Errno 2] No such file or directory: '/transformer_data/zhen\\\\vocab.src'\n"
     ]
    }
   ],
   "source": [
    "!echo $USR_DIR\n",
    "!python ./tensor2tensor/bin/t2t-decoder \\\n",
    "--t2t_usr_dir=$USR_DIR \\\n",
    "--data_dir=$DATA_DIR \\\n",
    "--problem=$PROBLEM \\\n",
    "--model=$MODEL \\\n",
    "--hparams_set=$HPARAMS \\\n",
    "--output_dir=$TRAIN_DIR \\\n",
    "--decode_hparams=\"beam_size=$BEAM_SIZE,alpha=$ALPHA,batch_size=32\" \\\n",
    "--decode_from_file=$DECODE_FILE \\\n",
    "--decode_to_file=$DATA_DIR/translation.en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f96dbd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
